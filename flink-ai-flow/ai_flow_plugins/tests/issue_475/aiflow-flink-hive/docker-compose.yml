version: "3"
networks:
  default:
    external: true
    name: app
services:
  # start hive part
  namenode:
    image: ${HADOOP_NAMENODE_IMAGE_FULL}
    container_name: namenode
    volumes:
      - namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./hadoop-hive.env
    ports:
      - ${HADOOP_NAMENODE_HTTP_PORT_EXTERNAL}:${HADOOP_NAMENODE_HTTP_PORT_INTERNAL}
  datanode:
    image: ${HADOOP_DATANODE_IMAGE_FULL}
    container_name: datanode
    volumes:
      - datanode:/hadoop/dfs/data
    env_file:
      - ./hadoop-hive.env
    environment:
      SERVICE_PRECONDITION: namenode:${HADOOP_NAMENODE_RPC_PORT}
    ports:
      - ${HADOOP_DATANODE_HTTP_PORT_EXTERNAL}:${HADOOP_DATANODE_HTTP_PORT_INTERNAL}
  hive-metastore-postgresql:
    container_name: hive-metastore-postgresql
    image: postgres:13-alpine3.14
    environment: 
      POSTGRES_DB: metastore
      POSTGRES_USER: hive
      POSTGRES_PASSWORD: hive
  hive-metastore-init:
    image: ${HIVE_IMAGE_FULL}
    container_name: hive-metastore-init
    env_file:
      - ${CONTEXT_DIR}/hadoop-hive.env
    command: /opt/hive/bin/schematool -dbType postgres -initSchema
    environment:
      SERVICE_PRECONDITION: hive-metastore-postgresql:5432
  hive-metastore:
    image: ${HIVE_IMAGE_FULL}
    container_name: hive-metastore
    env_file:
      - ${CONTEXT_DIR}/hadoop-hive.env
    command: /opt/hive/bin/hive --service metastore
    environment:
      SERVICE_PRECONDITION: namenode:${HADOOP_NAMENODE_RPC_PORT} datanode:${HADOOP_DATANODE_PORT} hive-metastore-postgresql:5432
    ports:
      - ${HIVE_THRIFT_PORT}:${HIVE_THRIFT_PORT}
    depends_on: 
      hive-metastore-init:
        condition: service_completed_successfully
  hive-server:
    image: ${HIVE_IMAGE_FULL}
    container_name: hive-server
    env_file:
      - ${CONTEXT_DIR}/hadoop-hive.env
    environment:
      HIVE_CORE_CONF_javax_jdo_option_ConnectionURL: "jdbc:postgresql://hive-metastore/metastore"
      SERVICE_PRECONDITION: hive-metastore:${HIVE_THRIFT_PORT}
    ports:
      - ${HIVE_SERVER2_WEB_PORT}:${HIVE_SERVER2_WEB_PORT}
  # presto-coordinator:
  #   image: shawnzhu/prestodb:0.181
  #   container_name: presto-coordinator
  #   ports:
  #     - "38080:8080"
  # end hive part

  # start flink part
  flink-jobmanager:
    container_name: flink-jobmanager
    image: ${FLINK_IMAGE_FULL}
    ports:
      - "38081:8081"
    command: jobmanager
    env_file:
      - ${CONTEXT_DIR}/hadoop-hive.env
    environment:
      - JOB_MANAGER_RPC_ADDRESS=flink-jobmanager
    volumes: 
      - ./sql-cli-defaults.yaml:/opt/flink/conf/sql-client-defaults.yaml
  flink-taskmanager:
    container_name: flink-taskmanager
    image: ${FLINK_IMAGE_FULL}
    depends_on:
      - flink-jobmanager
    command: taskmanager
    env_file:
      - ${CONTEXT_DIR}/hadoop-hive.env
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        taskmanager.numberOfTaskSlots: 2
        parallelism.default: 2  
    volumes: 
      - ./sql-cli-defaults.yaml:/opt/flink/conf/sql-client-defaults.yaml
  # end flink part

  # start ai-flow part
  flink-ai-flow-dev:
    image: ${DEV_IMAGE_FULL}
    container_name: flink-ai-flow-dev
    volumes:
      - ${ROOT_DIR}:/workspace:cached
    ports:
     - "8080:8080"
    command: /bin/sh -c "while sleep 1000; do :; done"
    env_file:
      - ${CONTEXT_DIR}/hadoop-hive.env
    environment: 
      AIFLOW_MYSQL_CONNECTION: mysql://${MYSQL_USER}:${MYSQL_PASSWORD}@${MYSQL_HOSTNAME}:${MYSQL_PORT}/aiflow
  flink-ai-flow-mysql:
    image: mysql:8
    container_name: flink-ai-flow-mysql
    environment:
      MYSQL_ROOT_PASSWORD: ${MYSQL_PASSWORD}
    restart: on-failure
    healthcheck:
      test:
        - CMD
        - mysql
        - -u
        - ${MYSQL_USER} 
        - -p${MYSQL_PASSWORD}
        - -e
        - "SHOW DATABASES;"
      timeout: 5s
      retries: 10
  mysql-init:
    image: mysql:8
    container_name: mysql-init
    depends_on: 
      flink-ai-flow-mysql:
        condition: service_healthy
    entrypoint: >
      /bin/bash -c "mysql -h ${MYSQL_HOSTNAME} -u ${MYSQL_USER} -p${MYSQL_PASSWORD} 
      -e \"CREATE DATABASE IF NOT EXISTS aiflow CHARACTER SET UTF8mb3 COLLATE utf8_general_ci;
      set global explicit_defaults_for_timestamp=1;\"
      "
  # end ai-flow part

volumes:
  namenode:
  datanode: